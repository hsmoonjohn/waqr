{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b9a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from DeepQuantile import DQR\n",
    "import numpy.random as rgt\n",
    "from scipy.stats import norm, t\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from WAQR import WAQR, FullyConnectedNN\n",
    "from joint import QuantES\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb857d1",
   "metadata": {},
   "source": [
    "# 1.Parametric Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46025450",
   "metadata": {},
   "source": [
    "This is an example of ES regression with $\\tau=0.1$, following DGP1 of Chetverikov, Liu and Tsyvinski (2022)\n",
    "where $Y=\\varepsilon+X'\\bar{\\beta}$ with $\\varepsilon\\sim N(0,1)$. Will use half to train the quantile model, and feed half to train the second step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "l2_err = np.zeros((B,3))\n",
    "out_l2_err = np.zeros((B,3))\n",
    "runtime = np.zeros((B,3))\n",
    "n = 3000 # number of training samples\n",
    "m = 5000 # number of test samples\n",
    "p = 5\n",
    "tau = 0.1\n",
    "\n",
    "betabar = np.array([0.3,0.5,0,0,0])\n",
    "betabar1=np.array([0.5,0.3,0.5,0,0,0])\n",
    "itc=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d41e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR = norm.ppf(tau)\n",
    "SQ = norm.ppf(1-tau)\n",
    "def tail_function(x) :\n",
    "    return (x if x < VaR else 0)\n",
    "\n",
    "def right_tail_function(x):\n",
    "    return (x if x >SQ else 0)\n",
    "\n",
    "CVaR = norm.expect(tail_function)/tau\n",
    "CSQ = norm.expect(right_tail_function)/tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(B):\n",
    "    X = np.random.standard_normal(size=(n, p))\n",
    "    Xbar= np.hstack((np.ones((n, 1)), X))\n",
    "    # Add a column of ones as the first column of the matrix\n",
    "    #X = np.hstack((np.ones((n, 1)), X))\n",
    "    err = rgt.normal(0,1,n)\n",
    "    Y = err +X.dot(betabar)+itc\n",
    "    X_test = np.random.standard_normal(size=(m, p))\n",
    "    # Add a column of ones as the first column of the matrix\n",
    "    X_test_bar = np.hstack((np.ones((m, 1)), X_test))\n",
    "    true_test_ES=X_test.dot(betabar) + CVaR +itc\n",
    "    true_test_SQ=X_test.dot(betabar) + CSQ +itc\n",
    "    \n",
    "    waqr1 = WAQR(Xbar,Y,options={'depth' : 3})\n",
    "    modells1 = waqr1.fit_ls(tau1=tau,intercept=False)\n",
    "    betahat=modells1.coef_\n",
    "    l2_err[b,0] = (np.mean((true_test_ES - modells1.predict(X_test_bar))**2))**0.5\n",
    "    \n",
    "    waqr2 = WAQR(Xbar,Y,options={'depth' : 3})\n",
    "    modelnl1, trainloss = waqr2.fit_nl(tau1=tau,hidden_sizes=[48],dropout_rate=0,lr=0.1, batch_size=32, use_lr_decay=True)\n",
    "    l2_err[b,1] = (np.mean((true_test_ES - modelnl1.predict(X_test_bar))**2))**0.5\n",
    "    \n",
    "    init = QuantES(X, Y)\n",
    "    ## two-step least squares\n",
    "    m1 = init.twostep_fit(tau=tau, loss='L2',standardize=True)\n",
    "    l2_err[b,2] = (np.mean((true_test_ES - X_test_bar.dot(m1['coef_e']))**2))**0.5\n",
    "    \n",
    "    #m2 = init.joint_fit(tau=tau)\n",
    "    #l2_err[b,2] = (np.mean((true_test_ES - X_test_bar.dot(m2['coef_e']))**2))**0.5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l2_err, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(trainloss), label='Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d2ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(trainloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a0e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a079c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c69b79",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 2. Nonparametric Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c962ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "l2_err_np = np.zeros((B,3))\n",
    "\n",
    "runtime = np.zeros((B,3))\n",
    "n = 3000 # number of training samples\n",
    "m = 5000 # number of test samples\n",
    "p = 4\n",
    "tau = 0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9e34d1",
   "metadata": {},
   "source": [
    "### (1)\n",
    "$$ y = \\sin(4\\pi x_1^2) \\sin(4\\pi x_2) + 2\\cos(4\\pi x_3) + x_4+\\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6de58f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonpar_function = lambda x : np.sin(4*np.pi*(x[:,0]))*np.sin(4*np.pi*x[:,1])+2*np.cos(4*np.pi*x[:,2])+x[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97caf389",
   "metadata": {},
   "outputs": [],
   "source": [
    "VaR = norm.ppf(tau)\n",
    "SQ = norm.ppf(1-tau)\n",
    "def tail_function(x) :\n",
    "    return (x if x < VaR else 0)\n",
    "\n",
    "def right_tail_function(x):\n",
    "    return (x if x >SQ else 0)\n",
    "\n",
    "CVaR = norm.expect(tail_function)/tau\n",
    "CSQ = norm.expect(right_tail_function)/tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09cd82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(B):\n",
    "    X = np.random.standard_normal(size=(n, p))\n",
    "    err = rgt.normal(0,1,n)\n",
    "    Y = err +nonpar_function(X)\n",
    "    X_test = np.random.standard_normal(size=(m, p))\n",
    "    X_test_bar = np.hstack((np.ones((m, 1)), X_test))\n",
    "    # Add a column of ones as the first column of the matrix\n",
    "    \n",
    "    true_test_ES=nonpar_function(X_test) + CVaR \n",
    "    true_test_SQ=nonpar_function(X_test) + CSQ \n",
    "    \n",
    "    waqr1 = WAQR(X,Y,options={'depth' : 3})\n",
    "    modells1 = waqr1.fit_ls(tau1=tau,weighting='es' ,intercept=True)\n",
    "    l2_err_np[b,0] = (np.mean((true_test_ES - modells1.predict(X_test))**2))**0.5\n",
    "    \n",
    "    waqr2 = WAQR(X,Y,options={'depth' : 3})\n",
    "    modelnl1,train_losses = waqr2.fit_nl(tau1=tau,weighting='es',hidden_sizes=[200,200,200],num_epochs=200,loss_function='Huber',dropout_rate=0,use_lr_decay=True,lr=0.1,batch_size=128, step_size=1,gamma=0.99)\n",
    "    l2_err_np[b,1] = (np.mean((true_test_ES - modelnl1.predict(X_test))**2))**0.5\n",
    "    \n",
    "    init = QuantES(X, Y)\n",
    "    ## two-step least squares\n",
    "    m1 = init.twostep_fit(tau=tau, loss='L2',standardize=True)\n",
    "    l2_err_np[b,2] = (np.mean((true_test_ES - X_test_bar.dot(m1['coef_e']))**2))**0.5\n",
    "    \n",
    "    #m2 = init.joint_fit(tau=tau)\n",
    "    #l2_err[b,2] = (np.mean((true_test_ES - X_test_bar.dot(m2['coef_e']))**2))**0.5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(l2_err_np, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47819b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(train_losses), label='Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a7b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad56c46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
